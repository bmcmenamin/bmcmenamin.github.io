---
layout: post
title: "New repo for Hebb-y meddling"
author: "Brenton McMenamin"
tags: [math&data, releases, hebbian-networks]
---

The reason I put together a package to do [factor analysis]({{ site.baseurl }}{% post_url 2017-09-12-releasing-fa-kit %}) is that I really like unsupervised methods for analyzing high-dimensional data. I think it all started after reading [Olshausen & Field's (1996)](https://www.nature.com/articles/381607a0) paper on how the behavior of visual system was consistent with a network that had performed unsupervised learning to develop a means of encoded images with a sparse code.

Recently, I've discovered a number of papers in the spirit of Olshausen & Field's work, except that they show that all of the learning can be accomplished with local Hebbian-like learning rules.
* [Hu, Pehlevan & Chklovskii (2015)](https://arxiv.org/abs/1503.00690)
* [Pehlevan & Chklovskii (2014)](https://arxiv.org/pdf/1503.00680)
* [Pehlevan & Chklovskii (2014)](https://arxiv.org/pdf/1511.09468)


So, I've started a [new repo](https://github.com/bmcmenamin/hebbnets) to implement some of their code and let me explore the power of Hebbian/Anti-Hebbian (HAH) networks.

At the moment, there is a single notebook demo showing that my HAH-network implementation can extract teh top principal component of a training set. I hope to do something more interesting soon.